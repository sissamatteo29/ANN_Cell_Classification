{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9944834,"sourceType":"datasetVersion","datasetId":6115050},{"sourceId":9976891,"sourceType":"datasetVersion","datasetId":6138718},{"sourceId":176958,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":150717,"modelId":173191}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Numeric computation\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras as tfk\nfrom tensorflow.keras import layers as tfkl\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom sklearn.utils import shuffle\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import (\n    accuracy_score,\n    confusion_matrix,\n    precision_score,\n    recall_score,\n    f1_score,\n)\n\n# Augmentation code\nimport keras_cv\n\n# Plotting\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"a8a9acf1-e191-4e8f-a3d6-1e5210a7e999","_cell_guid":"1b7fb12b-772e-4b1a-a450-ababe187fac2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:22.149534Z","iopub.execute_input":"2024-11-23T14:31:22.149889Z","iopub.status.idle":"2024-11-23T14:31:28.514967Z","shell.execute_reply.started":"2024-11-23T14:31:22.149847Z","shell.execute_reply":"2024-11-23T14:31:28.514193Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Setting seeds (for reproducibility purposes)","metadata":{"_uuid":"22f79fa9-8c1f-47b9-9b99-afd8507fbc47","_cell_guid":"4e22514c-edae-451e-92e0-e0110a12c756","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"seed = 42\nnp.random.seed(seed)\ntf.random.set_seed(seed)","metadata":{"_uuid":"1907075e-b6c2-4bc8-8901-e559a999ca13","_cell_guid":"1fb73dc9-6ef7-4154-8fb7-03b0fc031cbb","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:28.516972Z","iopub.execute_input":"2024-11-23T14:31:28.517583Z","iopub.status.idle":"2024-11-23T14:31:28.522502Z","shell.execute_reply.started":"2024-11-23T14:31:28.517549Z","shell.execute_reply":"2024-11-23T14:31:28.521432Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading dataset","metadata":{"_uuid":"afc240ac-153d-44dc-bf53-b77d5af7c27a","_cell_guid":"9c05dbae-7f0a-4acb-bafa-f9d748893136","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"file_path = \"/kaggle/input/cleandata/clean_data.npz\"\n\n\n# Load initial dataset and extract images and labels\ndata = np.load(file_path)\nimages, labels = data['images'], data['labels']\n\n\n# Inspect the content of the initial dataset (image size, label size...)\nprint(f\"Images shape: {images.shape}\")\nprint(f\"Labels shape: {labels.shape}\")\nprint(f\"Datatype images: {images.dtype}\")\n# print(images[0])","metadata":{"_uuid":"0c5cd4a2-9d4b-4123-97c3-7c25f6261992","_cell_guid":"0f36317e-89a5-4e84-8055-058d536473cd","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:28.523732Z","iopub.execute_input":"2024-11-23T14:31:28.524032Z","iopub.status.idle":"2024-11-23T14:31:30.273388Z","shell.execute_reply.started":"2024-11-23T14:31:28.523989Z","shell.execute_reply":"2024-11-23T14:31:30.272306Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Analysing the data and plotting some samples","metadata":{"_uuid":"28196a49-471f-4ae0-a7b7-bf19b1b7f981","_cell_guid":"37244467-3a67-4a05-9516-ecc39c75167c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Class labels\nlabels_dict = {\n    0: \"Basophil\",\n    1: \"Eosinophil\",\n    2: \"Erythroblast\",\n    3: \"Immature granulocytes\",\n    4: \"Lymphocyte\",\n    5: \"Monocyte\",\n    6: \"Neutrophil\",\n    7: \"Platelet\",\n}\n\n# Count number of instances of each class in the dataset\nclass_count = {}\nfor i in labels_dict:\n    class_count[i] = np.unique(labels, return_counts=True)[1][i]\n    \nprint(f\"The class distribution on the data set is: {class_count}\")\n\n# Plot some examples\nplot_img = images[:15]\n\nplt.figure(figsize=(16,9))\nfor i in range(15):\n    plt.subplot(3, 5, i + 1)\n    plt.imshow(plot_img[i])\n    plt.axis('off')","metadata":{"_uuid":"084ac877-25a9-4b68-8dd8-6a6aa486eef8","_cell_guid":"eb0fb2eb-679d-488c-a4e8-4ec118c45d44","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:30.274639Z","iopub.execute_input":"2024-11-23T14:31:30.274917Z","iopub.status.idle":"2024-11-23T14:31:31.239108Z","shell.execute_reply.started":"2024-11-23T14:31:30.274890Z","shell.execute_reply":"2024-11-23T14:31:31.238134Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing steps\n\nThe images are RGB images of shape 96x96x3. The preprocessing steps on the data are:\n- Convert labels into one-hot encoding\n- Split into train, validation and test sets\nNotice that data is automatically shuffled by the train_test_split function","metadata":{"_uuid":"e5185c07-b603-4391-b00f-c5d6eeb82acc","_cell_guid":"7a70bedb-e5b5-49de-9d40-0ad4c41b35b8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Tunable parameters\n# 10% of input data to both test and validation sets\ntest_ratio = 0.05 \nvalidation_ratio = 0.05 / 0.9 \n\n# Convert labels to one-hot encoding\nlabels = to_categorical(labels, num_classes=8).astype('float32')\n\n# Split data into (training & validation) and test sets\nx_train_val, x_test, y_train_val, y_test = train_test_split(images, labels, random_state=seed, test_size=test_ratio, stratify=np.argmax(labels,axis=1))\n\n# Further split train_val into train and validation sets\nx_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, random_state=seed, test_size=validation_ratio, stratify=np.argmax(y_train_val,axis=1))\n\n# Print shapes of the datasets\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\nprint(f\"x_val shape: {x_val.shape}, y_val shape: {y_val.shape}\")\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")","metadata":{"_uuid":"55a3dcdc-9dcb-46d6-92ec-8d402204ddb2","_cell_guid":"68b449c7-661b-4379-aa89-79f65d950b03","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:31.241086Z","iopub.execute_input":"2024-11-23T14:31:31.241401Z","iopub.status.idle":"2024-11-23T14:31:32.008819Z","shell.execute_reply.started":"2024-11-23T14:31:31.241347Z","shell.execute_reply":"2024-11-23T14:31:32.007807Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data augmentation pipeline (helper functions)\nData is augmented using different techniques, in particular a random pipeline, Cutmix, Fouriermix and Mixup","metadata":{"_uuid":"d070a087-925f-4949-b817-1f551671f724","_cell_guid":"2c436e3f-c4bf-461e-a12e-5a2fbd463a77","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Rescaling\n\ndef rescale_inputs(images, labels):\n    images = images * 255.0  # Scale normalized inputs [0, 1] to [0, 255]\n    return images, labels\n\n\ndef apply_mixup_cutmix(images, labels):\n\n    mixup = keras_cv.layers.MixUp(alpha=0.2)\n    cutmix = keras_cv.layers.CutMix(alpha=0.2)\n\n    # Randomly choose between CutMix, MixUp, or no augmentation\n    choice = tf.random.uniform([], minval=0, maxval=1, dtype=tf.int32)\n\n    if choice == 0:\n        augmented = mixup({\"images\": images, \"labels\": labels})\n    else:\n        augmented = cutmix({\"images\": images, \"labels\": labels})\n    \n    return augmented[\"images\"], augmented[\"labels\"]\n\n\n\ngeometric_pipeline = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),  # Randomly flip horizontally and vertically\n    tf.keras.layers.RandomRotation(0.2),  # Rotate up to ±20% of 360°\n    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),  # Translate up to 10%\n])\n\n# Random augmentations for images only\ndef geometric_pipeline_pretrain(images, labels):\n    images = geometric_pipeline(images)\n    return images, labels\n\n\n    \ncolour_pipeline = tf.keras.Sequential([\n    tf.keras.layers.RandomBrightness(factor=0.2, value_range=(0.0, 1.0)),  # Adjust brightness by ±20%\n    tf.keras.layers.RandomContrast(factor=0.2),  # Adjust contrast by ±20%\n    keras_cv.layers.RandomSaturation(factor=0.2),\n    keras_cv.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),\n])\n\ndef colour_pipeline_pretrain(images, labels):\n    images = colour_pipeline(images)\n    return images, labels\n\n\n\nmixed_pipeline = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),  # Randomly flip horizontally and vertically\n    tf.keras.layers.RandomRotation(0.2),  # Rotate up to ±20% of 360°\n    tf.keras.layers.RandomTranslation(height_factor=0.1, width_factor=0.1),  # Translate up to 10%\n    tf.keras.layers.RandomBrightness(factor=0.2, value_range=(0.0, 1.0)),  # Adjust brightness by ±20%\n    tf.keras.layers.RandomContrast(factor=0.2),  # Adjust contrast by ±20%\n])\n    \ndef mixed_pipeline_pretrain(images, labels):\n    images = mixed_pipeline(images)\n    return images, labels\n\n\n\ndef create_augmented_dataset_pretrain(images, labels, batch_size=64):\n    # Original dataset\n    original_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n\n    # Augmented dataset with random pipeline\n    aug_data_geometric = original_dataset.map(geometric_pipeline_pretrain, num_parallel_calls=tf.data.AUTOTUNE)\n    aug_data_colour = original_dataset.map(colour_pipeline_pretrain, num_parallel_calls=tf.data.AUTOTUNE)\n    aug_data_mixed = original_dataset.map(mixed_pipeline_pretrain, num_parallel_calls=tf.data.AUTOTUNE)\n\n    # Augmented dataset with MixUp and CutMix (batch-wise augmentation)\n    mixup_cutmix_dataset = (\n        original_dataset.batch(batch_size)\n        .map(apply_mixup_cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n        .unbatch()\n    )\n\n    # Combine all datasets: original + random augmented + MixUp/CutMix\n    full_dataset = original_dataset.concatenate(aug_data_geometric).concatenate(aug_data_colour).concatenate(aug_data_mixed).concatenate(mixup_cutmix_dataset)\n\n    # Shuffle, batch, and prefetch for efficiency\n    full_dataset = full_dataset.shuffle(buffer_size=len(images))\n    full_dataset = full_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE).repeat()\n\n    return full_dataset\n\n\n\n\n\n# AUGMENTED DATA FOR FINE TUNING (FEWER PIPELINES, MORE LIGHTWEIGHT TRANSFORMATIONS)\ngeometric_pipeline_ft = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),  # Randomly flip horizontally and vertically\n    tf.keras.layers.RandomRotation(0.1),  # Rotate up to ±20% of 360°\n    tf.keras.layers.RandomTranslation(height_factor=0.05, width_factor=0.05),  # Translate up to 10%\n])\n\n# Random augmentations for images only\ndef apply_geometric_pipeline_ft(images, labels):\n    images = geometric_pipeline_ft(images)\n    return images, labels\n\n\n    \ncolour_pipeline_ft = tf.keras.Sequential([\n    tf.keras.layers.RandomBrightness(factor=0.1, value_range=(0.0, 1.0)),  # Adjust brightness by ±20%\n    tf.keras.layers.RandomContrast(factor=0.1),  # Adjust contrast by ±20%\n    keras_cv.layers.RandomSaturation(factor=0.1),\n    keras_cv.layers.RandomTranslation(height_factor=0.05, width_factor=0.05),\n])\n\ndef apply_colour_pipeline_ft(images, labels):\n    images = colour_pipeline_ft(images)\n    return images, labels\n\n\n\nmixed_pipeline_ft = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),  # Randomly flip horizontally and vertically\n    tf.keras.layers.RandomRotation(0.1),  # Rotate up to ±20% of 360°\n    tf.keras.layers.RandomTranslation(height_factor=0.05, width_factor=0.05),  # Translate up to 10%\n    tf.keras.layers.RandomBrightness(factor=0.1, value_range=(0.0, 1.0)),  # Adjust brightness by ±20%\n    tf.keras.layers.RandomContrast(factor=0.1),  # Adjust contrast by ±20%\n])\n    \ndef apply_mixed_pipeline_ft(images, labels):\n    images = mixed_pipeline_ft(images)\n    return images, labels\n\n\n\ndef create_augmented_dataset_finetuning(images, labels, batch_size=64):\n    # Original dataset\n    original_dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n\n    # Augmented dataset with random pipeline\n    aug_data_geometric = original_dataset.map(apply_geometric_pipeline_ft, num_parallel_calls=tf.data.AUTOTUNE)\n    aug_data_colour = original_dataset.map(apply_colour_pipeline_ft, num_parallel_calls=tf.data.AUTOTUNE)\n    aug_data_mixed = original_dataset.map(apply_mixed_pipeline_ft, num_parallel_calls=tf.data.AUTOTUNE)\n\n    # Combine all datasets: original + random augmented + MixUp/CutMix\n    full_dataset = original_dataset.concatenate(aug_data_geometric).concatenate(aug_data_colour).concatenate(aug_data_mixed)\n\n    # Shuffle, batch, and prefetch for efficiency\n    full_dataset = full_dataset.shuffle(buffer_size=len(images))\n    full_dataset = full_dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE).repeat()\n\n    return full_dataset","metadata":{"_uuid":"f3ba1349-4a6f-401f-990d-396f3798b711","_cell_guid":"a8c6478a-abf2-4610-bfae-0ce734de5cfc","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:32.010347Z","iopub.execute_input":"2024-11-23T14:31:32.010660Z","iopub.status.idle":"2024-11-23T14:31:32.615867Z","shell.execute_reply.started":"2024-11-23T14:31:32.010633Z","shell.execute_reply":"2024-11-23T14:31:32.614764Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training parameters","metadata":{"_uuid":"91c64517-15af-4c91-9108-296aba9875fa","_cell_guid":"76782221-fb21-4ff9-957a-c1f9d89bb3df","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Training parameters\n\n# Input shape for the model\ninput_shape = x_train.shape[1:]\n\n# Output shape for the model\noutput_shape = y_train.shape[1]\n\n# Number of training epochs\nepochs = 75\n\n# Batch size for training\nbatch_size = 64 \n\n# Learning rate: step size for updating the model's weights\nlearning_rate = 0.001 \n\n# Define the patience value for early stopping\npatience = 7\n\n# Weighted loss function to compensate for underrepresentation of some classes\nclass_weights = compute_class_weight(\n    class_weight='balanced', \n    classes=np.unique(np.argmax(y_train, axis=1)), \n    y=np.argmax(y_train, axis=1)  # Convert one-hot labels to class indices\n)\n# Convert class weights to a dictionary\nclass_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n\n\n# Print the defined parameters\nprint(\"Input Shape:\", input_shape)\nprint(\"Output Shape:\", output_shape)\nprint(\"Epochs:\", epochs)\nprint(\"Batch Size:\", batch_size)\nprint(\"Learning Rate:\", learning_rate)\nprint(\"Class Weights:\", class_weights_dict)","metadata":{"_uuid":"9594c16e-69aa-41ad-855d-cd81391a4cef","_cell_guid":"188efcd6-9ef8-4b8c-a3fd-9c64bbf5da5b","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:32.617178Z","iopub.execute_input":"2024-11-23T14:31:32.617768Z","iopub.status.idle":"2024-11-23T14:31:32.628961Z","shell.execute_reply.started":"2024-11-23T14:31:32.617724Z","shell.execute_reply":"2024-11-23T14:31:32.627849Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Build the model","metadata":{"_uuid":"f6ead695-86a1-4ae4-b90c-98df88a90abe","_cell_guid":"857f990e-4042-479c-a0e2-e6aa8c32af99","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Backbone\nmodel_large = tfk.applications.ConvNeXtXLarge(\n    include_top=False, #can change this\n    include_preprocessing=True,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=input_shape,\n    pooling=\"avg\", #can change this\n    classes=8,\n    classifier_activation=\"softmax\"    \n)\ntfk.utils.plot_model(model_large, show_shapes=True)\n\nmodel_large.trainable = False #Freeze the weights of the CNN\ntf.random.set_seed(seed)\n\n# Create an input layer with shape (96, 96, 3)\ninputs = tfk.Input(shape=(96, 96, 3), name='input_layer')\n\naugmentation = tf.keras.Sequential([\n    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n    tfkl.RandomTranslation(0.2,0.2),\n    tfkl.RandomRotation(0.2),\n    tfkl.RandomZoom(0.2),\n], name='Augmentation')\n\nx = augmentation(inputs)\n\n# Connect ConvNeXtXLarge to the input\nx = model_large(x)\n\n###################################################################################################\n# Adding additional layers here\nx = tfkl.BatchNormalization()(x)\nx = tfkl.Dropout(0.5)(x)\n\nx = tfkl.Dense(512, activation='relu', name='dense1')(x)\nx = tfkl.BatchNormalization()(x)\nx = tfkl.Dropout(0.5)(x)\n\nx = tfkl.Dense(256, activation='relu', name='dense2')(x)\nx = tfkl.BatchNormalization()(x)\nx = tfkl.Dropout(0.5)(x)\n\nx = tfkl.Dense(128, activation='relu', name='dense3')(x)\nx = tfkl.BatchNormalization()(x)\nx = tfkl.Dropout(0.5)(x)\n###################################################################################################\n# Add a Dense layer with 8 units and softmax activation as the classifier\noutputs = tfkl.Dense(y_train.shape[-1], activation='softmax', name='dense')(x)\n\n# Create a Model connecting input and output\nmodel = tfk.Model(inputs=inputs, outputs=outputs, name='model')\n\n# Compile the model with Categorical Cross-Entropy loss and Adam optimizer\nmodel.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.AdamW(learning_rate), metrics=['accuracy'])\n\n# Display a summary of the model architecture\n# model.summary(expand_nested=True)\n\n# Display model architecture with layer shapes and trainable parameters\n# tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)\n\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',  \n    patience=patience,            \n    verbose=1,              \n    restore_best_weights=True  \n)\n\nreduce_lr = tfk.callbacks.ReduceLROnPlateau(\n    monitor=\"val_loss\", factor=0.5, patience=patience, min_lr=1e-6, verbose=1\n)\n\n# Store the callback in a list\ncallbacks = [reduce_lr, early_stopping]","metadata":{"_uuid":"213e7638-3397-4dfc-92d8-3c6053196353","_cell_guid":"bceef9fb-ddb3-4ef6-9dc2-29547a45e9c2","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2024-11-23T14:31:32.630333Z","iopub.execute_input":"2024-11-23T14:31:32.630770Z","iopub.status.idle":"2024-11-23T14:31:43.095311Z","shell.execute_reply.started":"2024-11-23T14:31:32.630713Z","shell.execute_reply":"2024-11-23T14:31:43.094524Z"},"_kg_hide-output":true,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Fine tuning\nThe process is going to be very similar to the previous one, but with a simplified augmented pipeline and no splitting of the data.","metadata":{"_uuid":"c0e1f2db-9431-45b4-9417-afd24ec38bb0","_cell_guid":"b706d9da-bfd6-4138-a4e9-08d718577f30","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Load previous best model\nmodel = tf.keras.models.load_model(\"/kaggle/input/convv/keras/default/1/best_model.keras\")\n\n# Set the ConvNeXtXLarge model layers as trainable\nmodel.get_layer('convnext_xlarge').trainable = True\n\n# Set all ConvNeXtXLarge layers as non-trainable\nfor layer in model.get_layer('convnext_xlarge').layers:\n    layer.trainable = False\n\n# Enable training only for Conv2D and DepthwiseConv2D layers\nfor i, layer in enumerate(model.get_layer('convnext_xlarge').layers):\n    if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.DepthwiseConv2D):\n        layer.trainable = True\n        print(i, layer.name, type(layer).__name__, layer.trainable)\n\n# Set the number of layers to freeze at the beginning of the network\nN = 124\n\n\n# Set the first N layers as non-trainable\nfor i, layer in enumerate(model.get_layer('convnext_xlarge').layers[:N]):\n    layer.trainable = False\n\n# Compile the model\nmodel.compile(loss=tfk.losses.CategoricalCrossentropy(), optimizer=tfk.optimizers.Adam(1e-4), metrics=['accuracy'])\n\n\n\ntrain_dataset = create_augmented_dataset_finetuning(images, labels)\nval_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n\naugmentation_steps_finetuning = 3\nsteps_per_epoch = (len(x_train) * (augmentation_steps_finetuning + 1)) // batch_size\n\n# Rescaling step needed for ConvNextXLarge\ntrain_dataset = train_dataset.map(rescale_inputs, num_parallel_calls=tf.data.AUTOTUNE)\nval_dataset = val_dataset.map(rescale_inputs, num_parallel_calls=tf.data.AUTOTUNE)\n\nhistory = model.fit(\n    train_dataset,\n    validation_data=val_dataset,\n    batch_size=batch_size,\n    epochs=epochs,\n    steps_per_epoch=steps_per_epoch,\n    callbacks = [tfk.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', patience=patience, restore_best_weights=True)],\n    class_weight=class_weights_dict,\n).history\n\n\n\nmodel_filename = 'model_large.keras'\n\nmodel.save(model_filename)","metadata":{"_uuid":"820a8d1f-70f4-44cf-96a3-3edb104c510f","_cell_guid":"03d0ef58-75fd-4dc5-a4e4-deee4f6ef3ef","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict class probabilities and get predicted classes\n\ntest_predictions = model.predict(x_test*255, verbose=0)\nprint(len(test_predictions))\ntest_predictions = np.argmax(test_predictions, axis=-1)\n\n# Extract ground truth classes\ntest_gt = np.argmax(y_test, axis=-1)\n\n# Calculate and display test set accuracy\ntest_accuracy = accuracy_score(test_gt, test_predictions)\nprint(f\"Accuracy score over the test set: {round(test_accuracy, 4)}\")\n\n# Calculate and display test set precision\ntest_precision = precision_score(test_gt, test_predictions, average=\"weighted\")\nprint(f\"Precision score over the test set: {round(test_precision, 4)}\")\n\n# Calculate and display test set recall\ntest_recall = recall_score(test_gt, test_predictions, average=\"weighted\")\nprint(f\"Recall score over the test set: {round(test_recall, 4)}\")\n\n# Calculate and display test set F1 score\ntest_f1 = f1_score(test_gt, test_predictions, average=\"weighted\")\nprint(f\"F1 score over the test set: {round(test_f1, 4)}\")\n\n# Compute the confusion matrix\ncm = confusion_matrix(test_gt, test_predictions)\n\n# Create labels combining confusion matrix values\nlabels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n\n# Plot the confusion matrix with class labels\nplt.figure(figsize=(8, 6))\nsns.heatmap(\n    cm,\n    annot=labels,\n    fmt=\"\",\n    xticklabels=list(labels_dict.values()),\n    yticklabels=list(labels_dict.values()),\n    cmap=\"Blues\",\n)\n\nplt.xlabel(\"True labels\")\nplt.ylabel(\"Predicted labels\")\nplt.show()\n\n\n# Delete the model to free up resources\ndel model","metadata":{"_uuid":"23fd32e3-08e6-4863-8799-bdc0f190288a","_cell_guid":"5930ca56-f25e-4a62-8257-be3b6415d049","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}