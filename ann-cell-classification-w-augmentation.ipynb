{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nuwVgG3Vbbka"
   },
   "source": [
    "# Artificial Neural Networks and Deep Learning\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7IqZP5Iblna"
   },
   "source": [
    "## ‚öôÔ∏è Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:57:39.924683Z",
     "iopub.status.busy": "2024-11-09T10:57:39.924202Z",
     "iopub.status.idle": "2024-11-09T10:57:56.060858Z",
     "shell.execute_reply": "2024-11-09T10:57:56.059776Z",
     "shell.execute_reply.started": "2024-11-09T10:57:39.924628Z"
    },
    "id": "CO6_Ft_8T56A",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow import keras as tfk\n",
    "from tensorflow.keras import layers as tfkl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN_cpHlSboXV"
   },
   "source": [
    "## ‚è≥ Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:57:56.063580Z",
     "iopub.status.busy": "2024-11-09T10:57:56.062939Z",
     "iopub.status.idle": "2024-11-09T10:58:00.759928Z",
     "shell.execute_reply": "2024-11-09T10:58:00.758594Z",
     "shell.execute_reply.started": "2024-11-09T10:57:56.063537Z"
    },
    "id": "pLaoDaG1V1Yg",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "data = np.load('training_set.npz')\n",
    "\n",
    "data\n",
    "x = data['images']\n",
    "y = data['labels']\n",
    "\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:00.770913Z",
     "iopub.status.busy": "2024-11-09T10:58:00.770452Z",
     "iopub.status.idle": "2024-11-09T10:58:00.790099Z",
     "shell.execute_reply": "2024-11-09T10:58:00.788678Z",
     "shell.execute_reply.started": "2024-11-09T10:58:00.770831Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Labels dictionary\n",
    "labels_dict = {\n",
    "    0: 'Basophil',\n",
    "    1: 'Eosinophil',\n",
    "    2: 'Erythroblast',\n",
    "    3: 'Immature granulocytes',\n",
    "    4: 'Lymphocyte',\n",
    "    5: 'Monocyte',\n",
    "    6: 'Neutrophil',\n",
    "    7: 'Platelet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count = {}\n",
    "for i in labels_dict:\n",
    "    class_count[i] = np.unique(y, return_counts=True)[1][i]\n",
    "\n",
    "class_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see image augmentation section to fix unbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:00.791865Z",
     "iopub.status.busy": "2024-11-09T10:58:00.791451Z",
     "iopub.status.idle": "2024-11-09T10:58:02.294079Z",
     "shell.execute_reply": "2024-11-09T10:58:02.292703Z",
     "shell.execute_reply.started": "2024-11-09T10:58:00.791820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(10, 10))\n",
    "axs = axs.reshape((-1,))\n",
    "for i in range(9):\n",
    "    axs[i].imshow(x[i])\n",
    "    axs[i].set_title(f'Class: {labels_dict[y[i][0]]} {y[i]}')\n",
    "    axs[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data to the range [0, 1]\n",
    "x = (x / 255).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_dict)\n",
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class `6: 'Neutrophil'` has the most images with 2530 samples. Have to augment to level all other classes to this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a sequential model for image augmentation\n",
    "augmentation = tf.keras.Sequential([\n",
    "    tfkl.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    tfkl.RandomTranslation(0.2,0.2),\n",
    "    tfkl.RandomRotation(0.2),\n",
    "    tfkl.RandomZoom(0.2),\n",
    "    tfkl.RandomBrightness(0.5, value_range=(0,1)),\n",
    "    tfkl.RandomContrast(0.75),\n",
    "], name='Augmentation')\n",
    "\n",
    "# Set up the figure and grid layout for displaying images\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10, 10))\n",
    "\n",
    "img = x[0] # Select the first image from the dataset for example\n",
    "\n",
    "# Display the original image\n",
    "axs[0].imshow(img)\n",
    "axs[0].axis('off')\n",
    "axs[0].set_title('Original Image')\n",
    "\n",
    "# Apply augmentation and display the first augmented image\n",
    "augmented_img = np.clip(augmentation(img), 0., 1.)\n",
    "axs[1].imshow(augmented_img)\n",
    "axs[1].axis('off')\n",
    "axs[1].set_title('Augmented Image 1')\n",
    "\n",
    "# Apply augmentation and display the second augmented image\n",
    "augmented_img = np.clip(augmentation(img), 0., 1.)\n",
    "axs[2].imshow(augmented_img)\n",
    "axs[2].axis('off')\n",
    "axs[2].set_title('Augmented Image 2')\n",
    "\n",
    "# Apply augmentation and display the third augmented image\n",
    "augmented_img = np.clip(augmentation(img), 0., 1.)\n",
    "axs[3].imshow(augmented_img)\n",
    "axs[3].axis('off')\n",
    "axs[3].set_title('Augmented Image 3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the augmentation layer that will be used for all classes to reach 2600 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_x = []\n",
    "new_y = []\n",
    "# Sweep for every class\n",
    "for clas in class_count:\n",
    "    print(f'Class: {clas}')\n",
    "    # Filter images of current class\n",
    "    class_images = x[y.flatten() == clas]\n",
    "    \n",
    "    while class_count[clas] < 2600:\n",
    "        # Select a random image from the current class\n",
    "        random_index = np.random.randint(0, class_images.shape[0])\n",
    "        original_img = class_images[random_index]\n",
    "        \n",
    "        # Apply augmentation layer\n",
    "        augmented_img = np.clip(augmentation(original_img), 0., 1.)\n",
    "        \n",
    "        # Add new image and its label to data\n",
    "        new_x.append(augmented_img)\n",
    "        new_y.append(clas)\n",
    "        \n",
    "        class_count[clas] += 1\n",
    "\n",
    "# Concatenate the augmented data into the whole data\n",
    "new_x = np.array(new_x)\n",
    "new_y = np.array(new_y).reshape(-1, 1)\n",
    "\n",
    "x = np.concatenate([x, new_x], axis=0)\n",
    "y = np.concatenate([y, new_y], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to categorical format using one-hot encoding\n",
    "y = tfk.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:04.760932Z",
     "iopub.status.busy": "2024-11-09T10:58:04.760484Z",
     "iopub.status.idle": "2024-11-09T10:58:05.686285Z",
     "shell.execute_reply": "2024-11-09T10:58:05.684931Z",
     "shell.execute_reply.started": "2024-11-09T10:58:04.760861Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_val_size = 0.05 # parameter to tune\n",
    "\n",
    "# Split data into train_val and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(x, y, random_state=seed, test_size=test_val_size, stratify=np.argmax(y,axis=1))\n",
    "\n",
    "# Further split train_val into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, random_state=seed, test_size=len(X_test), stratify=np.argmax(y_train_val,axis=1))\n",
    "\n",
    "# Print shapes of the datasets\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßÆ Define Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:05.688156Z",
     "iopub.status.busy": "2024-11-09T10:58:05.687757Z",
     "iopub.status.idle": "2024-11-09T10:58:05.695704Z",
     "shell.execute_reply": "2024-11-09T10:58:05.694315Z",
     "shell.execute_reply.started": "2024-11-09T10:58:05.688114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Input shape for the model\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "# Output shape for the model\n",
    "output_shape = y_train.shape[1]\n",
    "\n",
    "print(\"Input Shape:\", input_shape)\n",
    "print(\"Output Shape:\", output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:05.701611Z",
     "iopub.status.busy": "2024-11-09T10:58:05.701137Z",
     "iopub.status.idle": "2024-11-09T10:58:05.709050Z",
     "shell.execute_reply": "2024-11-09T10:58:05.707789Z",
     "shell.execute_reply.started": "2024-11-09T10:58:05.701561Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "epochs = 100 # parameter to tune\n",
    "\n",
    "# Batch size for training\n",
    "batch_size = 32 # parameter to tune\n",
    "\n",
    "# Learning rate: step size for updating the model's weights\n",
    "learning_rate = 0.001 # parameter to tune\n",
    "\n",
    "# Print the defined parameters\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Batch Size:\", batch_size)\n",
    "print(\"Learning Rate:\", learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:05.710484Z",
     "iopub.status.busy": "2024-11-09T10:58:05.710123Z",
     "iopub.status.idle": "2024-11-09T10:58:05.722695Z",
     "shell.execute_reply": "2024-11-09T10:58:05.721349Z",
     "shell.execute_reply.started": "2024-11-09T10:58:05.710445Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Todo: Add augmentation\n",
    "\n",
    "# # Define a data augmentation pipeline with random flip, brightness, and translation\n",
    "# augmentation = tf.keras.Sequential([\n",
    "#     tfkl.RandomFlip(\"horizontal\"),\n",
    "#     tfkl.RandomBrightness(0.2, value_range=(0,1)),\n",
    "#     tfkl.RandomTranslation(0.2,0.2),\n",
    "# ], name='preprocessing')\n",
    "\n",
    "# # Build the model with specified input and output shapes\n",
    "# model = build_model(augmentation=augmentation)\n",
    "\n",
    "# # Display a summary of the model architecture\n",
    "# model.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# # Plot the model architecture\n",
    "# tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:05.725333Z",
     "iopub.status.busy": "2024-11-09T10:58:05.724570Z",
     "iopub.status.idle": "2024-11-09T10:58:05.742446Z",
     "shell.execute_reply": "2024-11-09T10:58:05.741293Z",
     "shell.execute_reply.started": "2024-11-09T10:58:05.725289Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_model(\n",
    "    input_shape=input_shape,\n",
    "    output_shape=output_shape,\n",
    "    learning_rate=learning_rate,\n",
    "    augmentation=None,\n",
    "    seed=seed\n",
    "):\n",
    "\n",
    "    tf.random.set_seed(seed)\n",
    "    \n",
    "    # Build the neural network layer by layer\n",
    "    inputs = tfkl.Input(shape=input_shape, name='Input')\n",
    "\n",
    "    x = tfkl.Conv2D(filters=32, kernel_size=3, padding='same', name='conv1')(inputs)\n",
    "    x = tfkl.Activation('relu', name='act1')(x)\n",
    "    x = tfkl.MaxPooling2D(pool_size=2, name='mp1')(x)\n",
    "\n",
    "    x = tfkl.Conv2D(filters=64, kernel_size=3, padding='same', name='conv2')(x)\n",
    "    x = tfkl.Activation('relu', name='act2')(x)\n",
    "    x = tfkl.MaxPooling2D(pool_size=2, name='mp2')(x)\n",
    "\n",
    "    x = tfkl.Flatten(name='flatten')(x)\n",
    "\n",
    "    x = tfkl.Dense(units=output_shape, name='dense')(x)\n",
    "    outputs = tfkl.Activation('softmax', name='softmax')(x)\n",
    "\n",
    "    # Connect input and output through the Model class\n",
    "    model = tfk.Model(inputs=inputs, outputs=outputs, name='CNN')\n",
    "\n",
    "    # Compile the model\n",
    "    loss = tfk.losses.CategoricalCrossentropy()\n",
    "    optimizer = tfk.optimizers.Adam(learning_rate)\n",
    "    metrics = ['accuracy']\n",
    "    model.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "\n",
    "    # Return the model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:05.744612Z",
     "iopub.status.busy": "2024-11-09T10:58:05.744100Z",
     "iopub.status.idle": "2024-11-09T10:58:06.291710Z",
     "shell.execute_reply": "2024-11-09T10:58:06.290534Z",
     "shell.execute_reply.started": "2024-11-09T10:58:05.744555Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Build the model with specified input and output shapes\n",
    "model = build_model()\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary(expand_nested=True, show_trainable=True)\n",
    "\n",
    "# Plot the model architecture\n",
    "tfk.utils.plot_model(model, expand_nested=True, show_trainable=True, show_shapes=True, dpi=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FSliIxBvbs2Q"
   },
   "source": [
    "## üõ†Ô∏è Train and Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:06.293668Z",
     "iopub.status.busy": "2024-11-09T10:58:06.293214Z",
     "iopub.status.idle": "2024-11-09T10:58:06.300716Z",
     "shell.execute_reply": "2024-11-09T10:58:06.299435Z",
     "shell.execute_reply.started": "2024-11-09T10:58:06.293618Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the patience value for early stopping\n",
    "patience = 10 # parameter to tune\n",
    "\n",
    "# Create an EarlyStopping callback\n",
    "early_stopping = tfk.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=patience,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Store the callback in a list\n",
    "callbacks = [early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:06.302911Z",
     "iopub.status.busy": "2024-11-09T10:58:06.302485Z",
     "iopub.status.idle": "2024-11-09T10:58:06.314563Z",
     "shell.execute_reply": "2024-11-09T10:58:06.313356Z",
     "shell.execute_reply.started": "2024-11-09T10:58:06.302846Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-09T10:58:06.317234Z",
     "iopub.status.busy": "2024-11-09T10:58:06.316104Z"
    },
    "id": "ox9jqYyyUJo0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train the model with early stopping callback\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=callbacks\n",
    ").history\n",
    "\n",
    "# Calculate and print the final validation accuracy\n",
    "final_val_accuracy = round(max(history['val_accuracy'])* 100, 2)\n",
    "print(f'Final validation accuracy: {final_val_accuracy}%')\n",
    "\n",
    "# Save the trained model to a file with the accuracy included in the filename\n",
    "model_filename = 'CNN_'+str(final_val_accuracy)+'.keras'\n",
    "model.save(model_filename)\n",
    "\n",
    "# Delete the model to free up resources\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(history['loss'], label='Training loss', alpha=.8)\n",
    "plt.plot(history['val_loss'], label='Validation loss', alpha=.8)\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(15, 2))\n",
    "plt.plot(history['accuracy'], label='Training accuracy', alpha=.8)\n",
    "plt.plot(history['val_accuracy'], label='Validation accuracy', alpha=.8)\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üïπÔ∏è Use the Model - Make Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "'CNN_'+str(final_val_accuracy)+'.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T17:03:23.394696Z",
     "iopub.status.busy": "2024-11-08T17:03:23.394426Z",
     "iopub.status.idle": "2024-11-08T17:03:23.507975Z",
     "shell.execute_reply": "2024-11-08T17:03:23.507107Z",
     "shell.execute_reply.started": "2024-11-08T17:03:23.394665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "model = tfk.models.load_model('CNN_'+str(final_val_accuracy)+'.keras')\n",
    "\n",
    "# Display a summary of the model architecture\n",
    "model.summary(expand_nested=True, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-08T17:03:23.510209Z",
     "iopub.status.busy": "2024-11-08T17:03:23.509613Z",
     "iopub.status.idle": "2024-11-08T17:03:23.764851Z",
     "shell.execute_reply": "2024-11-08T17:03:23.763421Z",
     "shell.execute_reply.started": "2024-11-08T17:03:23.510175Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Predict class probabilities and get predicted classes\n",
    "test_predictions = model.predict(X_test, verbose=0)\n",
    "test_predictions = np.argmax(test_predictions, axis=-1)\n",
    "\n",
    "# Extract ground truth classes\n",
    "test_gt = np.argmax(y_test, axis=-1)\n",
    "\n",
    "# Calculate and display test set accuracy\n",
    "test_accuracy = accuracy_score(test_gt, test_predictions)\n",
    "print(f'Accuracy score over the test set: {round(test_accuracy, 4)}')\n",
    "\n",
    "# Calculate and display test set precision\n",
    "test_precision = precision_score(test_gt, test_predictions, average='weighted')\n",
    "print(f'Precision score over the test set: {round(test_precision, 4)}')\n",
    "\n",
    "# Calculate and display test set recall\n",
    "test_recall = recall_score(test_gt, test_predictions, average='weighted')\n",
    "print(f'Recall score over the test set: {round(test_recall, 4)}')\n",
    "\n",
    "# Calculate and display test set F1 score\n",
    "test_f1 = f1_score(test_gt, test_predictions, average='weighted')\n",
    "print(f'F1 score over the test set: {round(test_f1, 4)}')\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(test_gt, test_predictions)\n",
    "\n",
    "# Create labels combining confusion matrix values\n",
    "labels = np.array([f\"{num}\" for num in cm.flatten()]).reshape(cm.shape)\n",
    "\n",
    "# Plot the confusion matrix with class labels\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=labels, fmt='', xticklabels=list(labels_dict.values()), yticklabels=list(labels_dict.values()), cmap='Blues')\n",
    "plt.xlabel('True labels')\n",
    "plt.ylabel('Predicted labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RNp6pUZuddqC"
   },
   "source": [
    "## üìä Prepare Your Submission\n",
    "\n",
    "\n",
    "\n",
    "To prepare your submission, create a `.zip` file that includes all the necessary code to run your model. It **must** include a `model.py` file with the following class:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "# file: model.py\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        \"\"\"Initialize the internal state of the model.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"Return a numpy array with the labels corresponding to the input X.\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The next cell shows an example implementation of the `model.py` file, which includes loading model weights from the `weights.keras` file and conducting predictions on provided input data. The `.zip` file is created and downloaded in the last notebook cell.\n",
    "\n",
    "\n",
    "\n",
    "‚ùó Feel free to modify the method implementations to better fit your specific requirements, but please ensure that the class name and method interfaces remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKT4h-9xYwiT"
   },
   "outputs": [],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras as tfk\n",
    "\n",
    "from tensorflow.keras import layers as tfkl\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Model:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Initialize the internal state of the model. Note that the __init__\n",
    "\n",
    "        method cannot accept any arguments.\n",
    "\n",
    "\n",
    "\n",
    "        The following is an example loading the weights of a pre-trained\n",
    "\n",
    "        model.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        self.neural_network = tfk.models.load_model('CNN_83.28.keras')\n",
    "\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Predict the labels corresponding to the input X. Note that X is a numpy\n",
    "\n",
    "        array of shape (n_samples, 96, 96, 3) and the output should be a numpy\n",
    "\n",
    "        array of shape (n_samples,). Therefore, outputs must no be one-hot\n",
    "\n",
    "        encoded.\n",
    "\n",
    "\n",
    "\n",
    "        The following is an example of a prediction from the pre-trained model\n",
    "\n",
    "        loaded in the __init__ method.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        preds = self.neural_network.predict(X)\n",
    "\n",
    "        if len(preds.shape) == 2:\n",
    "\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s18kX1uDconq"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "filename = f'submission_{datetime.now().strftime(\"%y%m%d_%H%M%S\")}.zip'\n",
    "\n",
    "\n",
    "\n",
    "# Add files to the zip command if needed\n",
    "\n",
    "!zip {filename} model.py CNN_83.28.keras\n",
    "\n",
    "\n",
    "\n",
    "# from google.colab import files\n",
    "\n",
    "# files.download(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6040696,
     "sourceId": 9845641,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6042225,
     "sourceId": 9847610,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
